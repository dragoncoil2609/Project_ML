import streamlit as st
import pandas as pd
import pickle
import re
import nltk
from nltk.corpus import stopwords
import plotly.graph_objects as go
import numpy as np # C·∫ßn cho predict_proba

# --- C·∫§U H√åNH BAN ƒê·∫¶U ---
st.set_page_config(page_title="Demo Logistic Regression", layout="wide")
try:
    nltk.data.find('corpora/stopwords')
except LookupError:
    nltk.download('stopwords')

#=========================================================
# PH·∫¶N 1: T·∫¢I B·ªò N√ÉO (Logistic Regression)
#=========================================================
@st.cache_resource
def load_english_model():
    """T·∫£i m√¥ h√¨nh Logistic Regression  t·ª´ file .pkl"""
    try:
        with open('sentiment_model_english.pkl', 'rb') as f:
            model = pickle.load(f)
        
        with open('tfidf_vectorizer_english.pkl', 'rb') as f:
            vectorizer = pickle.load(f)
        
        print("T·∫£i m√¥ h√¨nh Logistic Regression  th√†nh c√¥ng!")
        return model, vectorizer
    except FileNotFoundError:
        print("L·ªñI: Kh√¥ng t√¨m th·∫•y file .pkl Ti·∫øng Anh.")
        st.error("L·ªñI: Kh√¥ng t√¨m th·∫•y file 'sentiment_model_english.pkl' ho·∫∑c 'tfidf_vectorizer_english.pkl'.")
        st.error("Vui l√≤ng ƒë·∫£m b·∫£o b·∫°n ƒë√£ xu·∫•t 2 file .pkl t·ª´ Notebook.")
        return None, None

# T·∫£i m√¥ h√¨nh
model, vectorizer = load_english_model()

#=========================================================
# PH·∫¶N 2: H√ÄM X·ª¨ L√ù (T·ª´ Notebook)
#=========================================================
def clean_text_english(text):
    """H√†m l√†m s·∫°ch vƒÉn b·∫£n (t·ª´ Notebook)"""
    text = str(text).lower()
    text = re.sub(r'[^\w\s]', '', text)
    text = re.sub(r'\d+', '', text)
    
    stop_words = set(stopwords.words('english'))
    words = text.split()
    cleaned_words = [word for word in words if word not in stop_words]
    
    return " ".join(cleaned_words)

#=========================================================
# PH·∫¶N 3: GIAO DI·ªÜN CH√çNH
#=========================================================
st.title("Sentiment Analysis with Logistic Regression")
st.subheader("D·ª± √°n M√¥ h√¨nh H·ªçc m√°y - Ph√¢n t√≠ch C·∫£m x√∫c B√¨nh lu·∫≠n S·∫£n ph·∫©m")

if model is None or vectorizer is None:
    st.error("Kh√¥ng th·ªÉ t·∫£i m√¥ h√¨nh. Vui l√≤ng ki·ªÉm tra file .pkl.")
else:
    # --- T√çNH NƒÇNG 1: PH√ÇN T√çCH TR·ª∞C TI·∫æP ---
    st.markdown("---")
    st.header("1. Ph√¢n t√≠ch Tr·ª±c ti·∫øp (Live Analysis)")
    
    col1, col2 = st.columns([0.6, 0.4])
    
    with col1:
        user_input_eng = st.text_area("Nh·∫≠p m·ªôt b√¨nh lu·∫≠n :", 
                                     "This product is absolutely fantastic! Highly recommended.", 
                                     height=100, key="eng_input")
        
        analyze_button_live = st.button("‚ú® Ph√¢n t√≠ch ngay!", key="live_button")

    with col2:
        st.markdown("### üîç K·∫øt qu·∫£ Ph√¢n t√≠ch")
        if analyze_button_live:
            if not user_input_eng.strip():
                st.warning("Vui l√≤ng nh·∫≠p m·ªôt b√¨nh lu·∫≠n .")
            else:
                with st.spinner("ƒêang x·ª≠ l√Ω..."):
                    # 1. L√†m s·∫°ch
                    cleaned_input = clean_text_english(user_input_eng)
                    # 2. Vector h√≥a
                    vectorized_input = vectorizer.transform([cleaned_input])
                    # 3. D·ª± ƒëo√°n
                    prediction = model.predict(vectorized_input)[0] # 0 ho·∫∑c 1
                    probability = model.predict_proba(vectorized_input)
                    confidence_score = np.max(probability)
                    
                if prediction == 1:
                    st.markdown("<h1 style='text-align: center; font-size: 80px;'>üëç</h1>", unsafe_allow_html=True)
                    st.success("T√çCH C·ª∞C (Positive)")
                else:
                    st.markdown("<h1 style='text-align: center; font-size: 80px;'>üëé</h1>", unsafe_allow_html=True)
                    st.error("TI√äU C·ª∞C (Negative)")
                
                st.progress(confidence_score)
                st.metric(label="ƒê·ªô t·ª± tin c·ªßa m√¥ h√¨nh:", value=f"{confidence_score * 100:.2f} %")


    # --- T√çNH NƒÇNG 2: PH√ÇN T√çCH V√ôNG D·ªÆ LI·ªÜU (M·ªöI) ---
    st.markdown("---")
    st.header("2. Ph√¢n t√≠ch D·ªØ li·ªáu D√°n (Paste-Box Analysis)")
    st.write("Copy v√† d√°n nhi·ªÅu b√¨nh lu·∫≠n t·ª´ web v√†o ƒë√¢y, m·ªói b√¨nh lu·∫≠n 1 d√≤ng.")

    paste_input = st.text_area("D√°n c√°c b√¨nh lu·∫≠n v√†o ƒë√¢y:", 
                               """This is a great product!
I hated this, it broke after one day.
Customer service was very helpful.
Not worth the money, sadly.
""", 
                               height=200, key="paste_input")
    
    analyze_button_paste = st.button("üöÄ Ph√¢n t√≠ch V√πng D·ªØ li·ªáu", key="paste_button")

    if analyze_button_paste:
        if not paste_input.strip():
            st.warning("Vui l√≤ng d√°n b√¨nh lu·∫≠n v√†o √¥.")
        else:
            with st.spinner("ƒêang ph√¢n t√≠ch v√πng d·ªØ li·ªáu..."):
                # T√°ch c√°c b√¨nh lu·∫≠n ra theo t·ª´ng d√≤ng
                lines = paste_input.splitlines()
                # Lo·∫°i b·ªè c√°c d√≤ng tr·ªëng
                reviews = [line.strip() for line in lines if line.strip()]
                
                if not reviews:
                    st.warning("Kh√¥ng t√¨m th·∫•y b√¨nh lu·∫≠n n√†o.")
                else:
                    # T·∫°o DataFrame t·∫°m
                    df_paste = pd.DataFrame(reviews, columns=['text_to_analyze'])
                    
                    # Ch·∫°y logic y h·ªát nh∆∞ Ph√¢n t√≠ch File
                    df_paste['cleaned_text'] = df_paste['text_to_analyze'].apply(clean_text_english)
                    X_new = vectorizer.transform(df_paste['cleaned_text'])
                    predictions = model.predict(X_new)
                    df_paste['Sentiment_Result'] = predictions
                    df_paste['Sentiment_Label'] = df_paste['Sentiment_Result'].map({1: 'Positive', 0: 'Negative'})
                    
                    st.success(f"Ph√¢n t√≠ch ho√†n t·∫•t {len(df_paste)} b√¨nh lu·∫≠n!")
                    
                    total_reviews = len(df_paste)
                    pos_count = (df_paste['Sentiment_Result'] == 1).sum()
                    neg_count = (df_paste['Sentiment_Result'] == 0).sum()

                    st.subheader(f"T·ªïng quan {total_reviews} b√¨nh lu·∫≠n ƒë√£ d√°n:")
                    col_metric1, col_metric2 = st.columns(2)
                    col_metric1.metric("üëç Positive", f"{pos_count} ({pos_count/total_reviews:.1%})")
                    col_metric2.metric("üëé Negative", f"{neg_count} ({neg_count/total_reviews:.1%})")
                    
                    fig = go.Figure(data=[go.Pie(labels=['Positive', 'Negative'],
                                                 values=[pos_count, neg_count],
                                                 marker={'colors': ['#28a745', '#dc3545']},
                                                 hole=.3)])
                    st.plotly_chart(fig, use_container_width=True)
                    
                    st.subheader("Chi ti·∫øt k·∫øt qu·∫£:")
                    st.dataframe(df_paste)


    # --- T√çNH NƒÇNG 3: PH√ÇN T√çCH H√ÄNG LO·∫†T (T·ª™ FILE) ---
    st.markdown("---")
    st.header("3. Ph√¢n t√≠ch H√†ng lo·∫°t (Batch Analysis)")
    st.write("T·∫£i l√™n file .csv ho·∫∑c .xlsx ch·ª©a ƒë√°nh gi√°  (t·ª´ d·ª± √°n Notebook).")
    
    uploaded_file = st.file_uploader("Ch·ªçn file...", type=["csv", "xlsx"], key="eng_uploader")
    
    if uploaded_file:
        # (To√†n b·ªô code x·ª≠ l√Ω file gi·ªØ nguy√™n nh∆∞ c≈©...)
        try:
            if uploaded_file.name.endswith('.csv'):
                df = pd.read_csv(uploaded_file)
            else:
                df = pd.read_excel(uploaded_file)
        except Exception as e:
            st.error(f"L·ªói khi ƒë·ªçc file: {e}")
            st.stop()

        st.info(f"ƒê√£ t·∫£i l√™n {len(df)} d√≤ng. Vui l√≤ng ch·ªçn c√°c c·ªôt vƒÉn b·∫£n .")
        
        available_cols = df.columns.tolist()
        default_cols = [col for col in ['Review', 'Summary', 'text'] if col in available_cols]
        
        col1_index = 0
        if default_cols:
            try: col1_index = available_cols.index(default_cols[0])
            except ValueError: col1_index = 0 

        col2_index = 0
        if len(default_cols) > 1:
            try: col2_index = available_cols.index(default_cols[1]) + 1
            except ValueError: col2_index = 0

        col1 = st.selectbox("C·ªôt 1 (v√≠ d·ª•: 'Review')", available_cols, index=col1_index, key="col1_eng")
        col2 = st.selectbox("C·ªôt 2 (v√≠ d·ª•: 'Summary') (T√πy ch·ªçn)", [None] + available_cols, index=col2_index, key="col2_eng")

        if st.button("üìä B·∫Øt ƒë·∫ßu Ph√¢n t√≠ch File", key="eng_button"):
            with st.spinner("ƒêang ph√¢n t√≠ch file ..."):
                if col2 and col2 != 'None':
                    df['text_to_analyze'] = df[col1].astype(str).fillna('') + " " + df[col2].astype(str).fillna('')
                else:
                    df['text_to_analyze'] = df[col1].astype(str).fillna('')

                df['cleaned_text'] = df['text_to_analyze'].apply(clean_text_english)
                X_new = vectorizer.transform(df['cleaned_text'])
                predictions = model.predict(X_new)
                df['Sentiment_Result'] = predictions
                df['Sentiment_Label'] = df['Sentiment_Result'].map({1: 'Positive', 0: 'Negative'})
            
            st.success("Ph√¢n t√≠ch file ho√†n t·∫•t!")
            
            total_reviews = len(df)
            pos_count = (df['Sentiment_Result'] == 1).sum()
            neg_count = (df['Sentiment_Result'] == 0).sum()

            st.subheader(f"T·ªïng quan tr√™n {total_reviews} ƒë√°nh gi√° :")
            col_metric1, col_metric2 = st.columns(2)
            col_metric1.metric("üëç Positive", f"{pos_count} ({pos_count/total_reviews:.1%})")
            col_metric2.metric("üëé Negative", f"{neg_count} ({neg_count/total_reviews:.1%})")
            
            fig = go.Figure(data=[go.Pie(labels=['Positive', 'Negative'],
                                         values=[pos_count, neg_count],
                                         marker={'colors': ['#28a745', '#dc3545']},
                                         hole=.3)])
            st.plotly_chart(fig, use_container_width=True)
            
            st.subheader("Xem chi ti·∫øt d·ªØ li·ªáu ƒë√£ ph√¢n t√≠ch ")
            st.dataframe(df)

            @st.cache_data
            def convert_df(df_to_convert):
                return df_to_convert.to_csv(index=False).encode('utf-8')
            csv_output = convert_df(df)
            st.download_button(label="üì• T·∫£i v·ªÅ k·∫øt qu·∫£ (CSV)", data=csv_output,
                               file_name="eng_sentiment_results.csv", mime="text/csv")