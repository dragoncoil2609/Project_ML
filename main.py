import streamlit as st
import pandas as pd
import pickle
import re
import nltk
from nltk.corpus import stopwords
import plotly.graph_objects as go
from transformers import pipeline
import time

# --- Cáº¤U HÃŒNH BAN Äáº¦U ---
st.set_page_config(page_title="Trá»£ lÃ½ Cáº£m xÃºc 2-trong-1", layout="wide")
try:
    nltk.data.find('corpora/stopwords')
except LookupError:
    nltk.download('stopwords') # Táº£i stop words cho mÃ´ hÃ¬nh Tiáº¿ng Anh

#=========================================================
# PHáº¦N 1: Táº¢I CÃC Bá»˜ NÃƒO (MODELS)
#=========================================================

# --- NÃ£o 1: PhoBERT (Tiáº¿ng Viá»‡t) ---
@st.cache_resource
def load_phobert_model():
    """Táº£i mÃ´ hÃ¬nh PhoBERT (Tiáº¿ng Viá»‡t) tá»« thÆ° má»¥c LOCAL."""
    model_name = "phobert_model" 
    try:
        sentiment_pipeline = pipeline(
            "sentiment-analysis", 
            model=model_name,
            use_fast=False
        )
        print("Táº£i mÃ´ hÃ¬nh PhoBERT (Tiáº¿ng Viá»‡t) thÃ nh cÃ´ng!")
        return sentiment_pipeline
    except Exception as e:
        print(f"Lá»–I KHI Táº¢I MODEL POBERT LOCAL: {e}")
        return None

# --- NÃ£o 2: Logistic Regression (Tiáº¿ng Anh) ---
@st.cache_resource
def load_english_model():
    """Táº£i mÃ´ hÃ¬nh Logistic Regression (Tiáº¿ng Anh) tá»« file .pkl"""
    try:
        with open('sentiment_model_english.pkl', 'rb') as f:
            model = pickle.load(f)
        
        with open('tfidf_vectorizer_english.pkl', 'rb') as f:
            vectorizer = pickle.load(f)
        
        print("Táº£i mÃ´ hÃ¬nh Logistic Regression (Tiáº¿ng Anh) thÃ nh cÃ´ng!")
        return model, vectorizer
    except FileNotFoundError:
        print("Lá»–I: KhÃ´ng tÃ¬m tháº¥y file .pkl Tiáº¿ng Anh.")
        return None, None

#=========================================================
# PHáº¦N 2: CÃC HÃ€M Xá»¬ LÃ (CHO Cáº¢ 2 MODELS)
#=========================================================

# --- HÃ m cho NÃ£o 1 (PhoBERT) ---
def analyze_fragments_vietnamese(text, ai_pipeline):
    """TÃ¡ch cÃ¢u Tiáº¿ng Viá»‡t thÃ nh cÃ¡c váº¿ vÃ  phÃ¢n tÃ­ch."""
    # Logic tÃ¡ch cÃ¢u Ä‘Ã£ sá»­a
    split_words = [',', 'nhÆ°ng', 'tuy nhiÃªn', 'tuy váº­y', 'dÃ¹', 'máº·c dÃ¹', 'thay vÃ o Ä‘Ã³']
    split_pattern = r'(' + ' | '.join(re.escape(word) for word in split_words) + ' )'
    fragments = re.split(split_pattern, text)
    
    final_fragments = []
    temp_frag = ""
    for frag in fragments:
        if frag.strip() in split_words:
            temp_frag = frag + " "
        elif frag.strip():
            final_fragments.append((temp_frag + frag).strip())
            temp_frag = ""
            
    cleaned_fragments = [f for f in final_fragments if f and len(f.split()) > 1] 
    if len(cleaned_fragments) <= 1: return []

    results = []
    for frag in cleaned_fragments:
        result = ai_pipeline(frag)[0]
        results.append((frag, result['label'], result['score']))
    return results

# --- HÃ m cho NÃ£o 2 (Logistic Regression) ---
def clean_text_english(text):
    """HÃ m lÃ m sáº¡ch vÄƒn báº£n Tiáº¿ng Anh (tá»« Notebook)"""
    text = str(text).lower() # Chuyá»ƒn thÃ nh chá»¯ thÆ°á»ng
    text = re.sub(r'[^\w\s]', '', text) # XÃ³a kÃ½ tá»± Ä‘áº·c biá»‡t, dáº¥u cÃ¢u
    text = re.sub(r'\d+', '', text) # XÃ³a sá»‘
    
    stop_words = set(stopwords.words('english'))
    words = text.split()
    cleaned_words = [word for word in words if word not in stop_words]
    
    return " ".join(cleaned_words)

#=========================================================
# PHáº¦N 3: GIAO DIá»†N CHÃNH (DÃ™NG TABS)
#=========================================================

st.title("ğŸš€ Trá»£ lÃ½ Cáº£m xÃºc AI 2-trong-1")

# Táº£i cáº£ 2 mÃ´ hÃ¬nh
phobert_pipeline = load_phobert_model()
eng_model, eng_vectorizer = load_english_model()

# Táº¡o 2 Tabs
tab1, tab2 = st.tabs(["PhÃ¢n tÃ­ch Trá»±c tiáº¿p", 
                      "PhÃ¢n tÃ­ch File "])

# --- TAB 1: GIAO DIá»†N PHOBERT (TIáº¾NG VIá»†T) ---
with tab1:
    if phobert_pipeline is None:
        st.error("Lá»—i táº£i mÃ´ hÃ¬nh PhoBERT (Tiáº¿ng Viá»‡t). Vui lÃ²ng kiá»ƒm tra thÆ° má»¥c 'phobert_model'.")
    else:
        st.header("Sá»­ dá»¥ng Deep Learning (PhoBERT) Ä‘á»ƒ bÃ³c tÃ¡ch ngá»¯ cáº£nh")
        
        col1, col2 = st.columns([0.6, 0.4])
        
        with col1:
            user_input_vi = st.text_area("Nháº­p bÃ¬nh luáº­n Tiáº¿ng Viá»‡t:", 
                                         "Ã¡o thÃ¬ Ä‘áº¹p, nhÆ°ng phÃ­ ship quÃ¡ Ä‘áº¯t thay vÃ o Ä‘Ã³ nhÃ¢n viÃªn nhiá»‡t tÃ¬nh", 
                                         height=150, key="vi_input")
            analyze_button_vi = st.button("âœ¨ PhÃ¢n tÃ­ch ngay!", key="vi_button")
            
            st.markdown("---")
            st.markdown("#### ğŸ’¡ Gá»£i Ã½ thá»­ nghiá»‡m:")
            st.info("Thá»­ nháº­p má»™t cÃ¢u cÃ³ nhiá»u váº¿ cáº£m xÃºc trÃ¡i ngÆ°á»£c nhau, vÃ­ dá»¥:\n\n"
                    "* `Quáº§n Ã¡o shop nÃ y Ä‘áº¹p, nhÆ°ng giÃ¡ hÆ¡i chÃ¡t.`\n"
                    "* `Dá»‹ch vá»¥ tá»‘t, Ä‘á»“ Äƒn táº¡m Ä‘Æ°á»£c, sáº½ quay láº¡i.`\n"
                    "* `Máº·c dÃ¹ giao hÃ ng cháº­m, sáº£n pháº©m ráº¥t tuyá»‡t vá»i.`")

        with col2:
            st.markdown("### ğŸ” Káº¿t quáº£ PhÃ¢n tÃ­ch (Tiáº¿ng Viá»‡t)")
            if analyze_button_vi:
                if not user_input_vi.strip():
                    st.warning("Vui lÃ²ng nháº­p bÃ¬nh luáº­n Tiáº¿ng Viá»‡t.")
                else:
                    # PhÃ¢n tÃ­ch tá»•ng thá»ƒ
                    st.markdown("#### 1. Cáº£m xÃºc tá»•ng thá»ƒ:")
                    with st.spinner("AI Ä‘ang suy nghÄ© (Tá»•ng thá»ƒ)..."):
                        time.sleep(0.3)
                        result_vi = phobert_pipeline(user_input_vi)[0]
                        label = result_vi['label']
                        score = result_vi['score']

                    if label == 'POS':
                        st.markdown("<h1 style='text-align: center; font-size: 80px;'>ğŸ˜„</h1>", unsafe_allow_html=True)
                        st.success("TÃCH Cá»°C (Positive)")
                    elif label == 'NEG':
                        st.markdown("<h1 style='text-align: center; font-size: 80px;'>ğŸ˜¡</h1>", unsafe_allow_html=True)
                        st.error("TIÃŠU Cá»°C (Negative)")
                    else: # 'NEU'
                        st.markdown("<h1 style='text-align: center; font-size: 80px;'>ğŸ˜</h1>", unsafe_allow_html=True)
                        st.info("TRUNG Láº¬P (Neutral)")
                    
                    st.progress(score)
                    st.metric(label="Äá»™ tá»± tin (Tá»•ng thá»ƒ):", value=f"{score * 100:.2f} %")

                    # PhÃ¢n tÃ­ch bÃ³c tÃ¡ch
                    st.markdown("---")
                    st.markdown("#### 2. PhÃ¢n tÃ­ch bÃ³c tÃ¡ch (ChuyÃªn sÃ¢u):")
                    with st.spinner("AI Ä‘ang bÃ³c tÃ¡ch cÃ¢u..."):
                        fragments_vi = analyze_fragments_vietnamese(user_input_vi, phobert_pipeline)
                    
                    if not fragments_vi:
                        st.write("CÃ¢u nÃ y Ä‘Æ¡n giáº£n, khÃ´ng cÃ³ váº¿ phá»¥ Ä‘á»ƒ bÃ³c tÃ¡ch.")
                    else:
                        st.write("AI nháº­n tháº¥y cÃ¢u nÃ y cÃ³ nhiá»u váº¿ cáº£m xÃºc:")
                        for frag, label, score in fragments_vi:
                            frag_text = f"**Váº¿ cÃ¢u:** `\"{frag}\"`"
                            if label == 'POS':
                                st.success(f"{frag_text} â TÃCH Cá»°C ({score*100:.0f}%)")
                            elif label == 'NEG':
                                st.error(f"{frag_text} â TIÃŠU Cá»°C ({score*100:.0f}%)")
                            else:
                                st.info(f"{frag_text} â TRUNG Láº¬P ({score*100:.0f}%)")

# --- TAB 2: GIAO DIá»†N LOGISTIC REGRESSION (TIáº¾NG ANH) ---
with tab2:
    if eng_model is None or eng_vectorizer is None:
        st.error("Lá»—i táº£i mÃ´ hÃ¬nh Tiáº¿ng Anh. Vui lÃ²ng kiá»ƒm tra 2 file .pkl Ä‘Ã£ Ä‘Æ°á»£c xuáº¥t ra tá»« Notebook.")
    else:
        st.header("PhÃ¢n tÃ­ch Cáº£m xÃºc File (Logistic Regression - Tiáº¿ng Anh)")
        st.write("Táº£i lÃªn file .csv hoáº·c .xlsx chá»©a Ä‘Ã¡nh giÃ¡ Tiáº¿ng Anh cá»§a báº¡n (tá»« dá»± Ã¡n Notebook).")
        
        uploaded_file = st.file_uploader("Chá»n file...", type=["csv", "xlsx"], key="eng_uploader")
        
        if uploaded_file:
            # Äá»c file
            try:
                if uploaded_file.name.endswith('.csv'):
                    df = pd.read_csv(uploaded_file)
                else:
                    df = pd.read_excel(uploaded_file)
            except Exception as e:
                st.error(f"Lá»—i khi Ä‘á»c file: {e}")
                st.stop()

            st.info(f"ÄÃ£ táº£i lÃªn {len(df)} dÃ²ng. Vui lÃ²ng chá»n cÃ¡c cá»™t vÄƒn báº£n (Tiáº¿ng Anh).")
            
            # Chá»n cá»™t
            available_cols = df.columns.tolist()
            default_cols = [col for col in ['Review', 'Summary', 'text'] if col in available_cols]
            
            col1_index = 0
            if default_cols:
                try:
                    col1_index = available_cols.index(default_cols[0])
                except ValueError:
                    col1_index = 0 

            col2_index = 0
            if len(default_cols) > 1:
                try:
                    col2_index = available_cols.index(default_cols[1]) + 1
                except ValueError:
                    col2_index = 0

            col1 = st.selectbox("Cá»™t 1 (vÃ­ dá»¥: 'Review')", available_cols, index=col1_index, key="col1_eng")
            col2 = st.selectbox("Cá»™t 2 (vÃ­ dá»¥: 'Summary') (TÃ¹y chá»n)", [None] + available_cols, index=col2_index, key="col2_eng")

            if st.button("ğŸ“Š Báº¯t Ä‘áº§u PhÃ¢n tÃ­ch File", key="eng_button"):
                with st.spinner("Äang phÃ¢n tÃ­ch file Tiáº¿ng Anh..."):
                    # 1. Táº¡o cá»™t 'text'
                    if col2 and col2 != 'None':
                        df['text_to_analyze'] = df[col1].astype(str).fillna('') + " " + df[col2].astype(str).fillna('')
                    else:
                        df['text_to_analyze'] = df[col1].astype(str).fillna('')

                    # 2. LÃ m sáº¡ch (theo logic Notebook)
                    df['cleaned_text'] = df['text_to_analyze'].apply(clean_text_english)

                    # 3. Vector hÃ³a
                    X_new = eng_vectorizer.transform(df['cleaned_text'])

                    # 4. Dá»± Ä‘oÃ¡n
                    predictions = eng_model.predict(X_new) # 0 hoáº·c 1
                    df['Sentiment_Result'] = predictions
                    df['Sentiment_Label'] = df['Sentiment_Result'].map({1: 'Positive', 0: 'Negative'})
                
                st.success("PhÃ¢n tÃ­ch file hoÃ n táº¥t!")
                
                # Hiá»ƒn thá»‹ káº¿t quáº£
                total_reviews = len(df)
                pos_count = (df['Sentiment_Result'] == 1).sum()
                neg_count = (df['Sentiment_Result'] == 0).sum()

                st.subheader(f"Tá»•ng quan trÃªn {total_reviews} Ä‘Ã¡nh giÃ¡ (Tiáº¿ng Anh):")
                col_metric1, col_metric2 = st.columns(2)
                col_metric1.metric("ğŸ‘ Positive", f"{pos_count} ({pos_count/total_reviews:.1%})")
                col_metric2.metric("ğŸ‘ Negative", f"{neg_count} ({neg_count/total_reviews:.1%})")
                
                # === ÄÃ‚Y LÃ€ DÃ’NG ÄÃƒ Sá»¬A Lá»–I ===
                fig = go.Figure(data=[go.Pie(labels=['Positive', 'Negative'],
                                             values=[pos_count, neg_count],
                                             marker={'colors': ['#28a745', '#dc3545']}, # Sá»­a á»Ÿ Ä‘Ã¢y
                                             hole=.3)])
                st.plotly_chart(fig, use_container_width=True)
                
                st.subheader("Xem chi tiáº¿t dá»¯ liá»‡u Ä‘Ã£ phÃ¢n tÃ­ch (Tiáº¿ng Anh)")
                st.dataframe(df)

                # Táº£i vá»
                @st.cache_data
                def convert_df(df_to_convert):
                    return df_to_convert.to_csv(index=False).encode('utf-8')

                csv_output = convert_df(df)
                
                st.download_button(label="ğŸ“¥ Táº£i vá» káº¿t quáº£ (CSV)", data=csv_output,
                                   file_name="eng_sentiment_results.csv", mime="text/csv")