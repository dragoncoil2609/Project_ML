import streamlit as st
import pandas as pd
import pickle
import re
import nltk
from nltk.corpus import stopwords
import plotly.graph_objects as go
import numpy as np
import sqlite3
import bcrypt

# --- C·∫§U H√åNH BAN ƒê·∫¶U ---
st.set_page_config(page_title="Demo Logistic Regression", layout="wide")
try:
    nltk.data.find('corpora/stopwords')
except LookupError:
    nltk.download('stopwords')

#=========================================================
# PH·∫¶N 1: K·∫æT N·ªêI DATABASE V√Ä C√ÅC H√ÄM X·ª¨ L√ù
#=========================================================
# (C√°c h√†m n√†y gi·ªØ nguy√™n)
def get_db_connection():
    return sqlite3.connect('users.db')

def hash_password(password):
    return bcrypt.hashpw(password.encode('utf-8'), bcrypt.gensalt())

def check_password(password, hashed):
    return bcrypt.checkpw(password.encode('utf-8'), hashed)

def save_history(username, analysis_type, input_text, result_label, result_score):
    conn = get_db_connection()
    cursor = conn.cursor()
    cursor.execute(
        "INSERT INTO history (username, analysis_type, input_text, result_label, result_score) VALUES (?, ?, ?, ?, ?)",
        (username, analysis_type, input_text, result_label, result_score)
    )
    conn.commit()
    conn.close()

def get_user_history(username):
    conn = get_db_connection()
    cursor = conn.cursor()
    cursor.execute("SELECT timestamp, analysis_type, input_text, result_label, result_score FROM history WHERE username = ? ORDER BY timestamp DESC", (username,))
    history_df = pd.DataFrame(cursor.fetchall(), columns=['Th·ªùi gian', 'Lo·∫°i', 'Input', 'K·∫øt qu·∫£', 'ƒê·ªô t·ª± tin'])
    conn.close()
    return history_df

#=========================================================
# PH·∫¶N 2: T·∫¢I B·ªò N√ÉO AI (Logistic Regression)
#=========================================================
@st.cache_resource
def load_english_model():
    # (Gi·ªØ nguy√™n h√†m n√†y)
    try:
        with open('sentiment_model_english.pkl', 'rb') as f:
            model = pickle.load(f)
        with open('tfidf_vectorizer_english.pkl', 'rb') as f:
            vectorizer = pickle.load(f)
        return model, vectorizer
    except FileNotFoundError:
        st.error("L·ªñI: Kh√¥ng t√¨m th·∫•y file .pkl.")
        return None, None

model, vectorizer = load_english_model()

#=========================================================
# PH·∫¶N 3: H√ÄM X·ª¨ L√ù VƒÇN B·∫¢N (T·ª´ Notebook)
#=========================================================
def clean_text_english(text):
    # (Gi·ªØ nguy√™n h√†m n√†y)
    text = str(text).lower()
    text = re.sub(r'[^\w\s]', '', text)
    text = re.sub(r'\d+', '', text)
    stop_words = set(stopwords.words('english'))
    words = text.split()
    cleaned_words = [word for word in words if word not in stop_words]
    return " ".join(cleaned_words)

#=========================================================
# PH·∫¶N 4: GIAO DI·ªÜN CH√çNH (ƒêƒÉng nh·∫≠p / ƒêƒÉng k√Ω T·ª∞ L√ÄM)
#=========================================================

# Kh·ªüi t·∫°o session state
if 'authentication_status' not in st.session_state:
    st.session_state['authentication_status'] = None
if 'username' not in st.session_state:
    st.session_state['username'] = None
if 'name' not in st.session_state:
    st.session_state['name'] = None

# --- N·∫øu CH∆ØA ƒêƒÇNG NH·∫¨P ---
if not st.session_state['authentication_status']:
    col_login, col_intro = st.columns([0.5, 0.5]) 

    with col_intro:
        st.title("Sentiment Analysis with Logistic Regression")
        st.markdown("")
        st.markdown("""
        ·ª®ng d·ª•ng n√†y s·ª≠ d·ª•ng m√¥ h√¨nh **Logistic Regression** ƒë√£ ƒë∆∞·ª£c hu·∫•n luy·ªán tr√™n
        d·ªØ li·ªáu ƒë·ªÉ:
        * Ph√¢n t√≠ch c·∫£m x√∫c (T√≠ch c·ª±c/Ti√™u c·ª±c) c·ªßa m·ªôt c√¢u.
        * Ph√¢n t√≠ch h√†ng lo·∫°t b√¨nh lu·∫≠n (d√°n v√†o ho·∫∑c t·∫£i file).
        
        Vui l√≤ng **ƒêƒÉng nh·∫≠p** ho·∫∑c **ƒêƒÉng k√Ω** (·ªü b√™n tr√°i) ƒë·ªÉ b·∫Øt ƒë·∫ßu.
        """)

    with col_login:
        
        st.subheader("B·∫£ng ƒëi·ªÅu khi·ªÉn")
        tab_login, tab_register = st.tabs(["üîë ƒêƒÉng nh·∫≠p", "üë§ ƒêƒÉng k√Ω"])

        # --- Tab ƒêƒÉng nh·∫≠p ---
        with tab_login:
            with st.form("login_form"):
                username = st.text_input("T√™n ƒëƒÉng nh·∫≠p")
                password = st.text_input("M·∫≠t kh·∫©u", type="password")
                login_button = st.form_submit_button("ƒêƒÉng nh·∫≠p")

                if login_button:
                    if not (username and password):
                        st.warning("Vui l√≤ng nh·∫≠p ƒë·ªß t√™n ƒëƒÉng nh·∫≠p v√† m·∫≠t kh·∫©u.")
                    else:
                        conn = get_db_connection()
                        cursor = conn.cursor()
                        cursor.execute("SELECT name, password_hash FROM users WHERE username = ?", (username,))
                        user_data = cursor.fetchone()
                        conn.close()
                        
                        if user_data and check_password(password, user_data[1]):
                            st.session_state['authentication_status'] = True
                            st.session_state['username'] = username
                            st.session_state['name'] = user_data[0]
                            st.rerun() 
                        else:
                            st.error("T√™n ƒëƒÉng nh·∫≠p ho·∫∑c m·∫≠t kh·∫©u kh√¥ng ƒë√∫ng.")

        # --- Tab ƒêƒÉng k√Ω ---
        with tab_register:
            with st.form("register_form"):
                name = st.text_input("T√™n c·ªßa b·∫°n (v√≠ d·ª•: 'Hoang Van A')")
                username = st.text_input("T√™n ƒëƒÉng nh·∫≠p (d√πng ƒë·ªÉ login)")
                password = st.text_input("M·∫≠t kh·∫©u", type="password")
                r_password = st.text_input("Nh·∫≠p l·∫°i M·∫≠t kh·∫©u", type="password")
                register_button = st.form_submit_button("ƒêƒÉng k√Ω")

                if register_button:
                    if not (name and username and password and r_password):
                        st.error("Vui l√≤ng ƒëi·ªÅn ƒë·∫ßy ƒë·ªß th√¥ng tin.")
                    elif password != r_password:
                        st.error("M·∫≠t kh·∫©u nh·∫≠p l·∫°i kh√¥ng kh·ªõp.")
                    else:
                        try:
                            hashed_pass = hash_password(password)
                            conn = get_db_connection()
                            cursor = conn.cursor()
                            cursor.execute("INSERT INTO users (username, password_hash, name) VALUES (?, ?, ?)", (username, hashed_pass, name))
                            conn.commit()
                            conn.close()
                            st.success("ƒêƒÉng k√Ω th√†nh c√¥ng! Vui l√≤ng chuy·ªÉn qua tab 'ƒêƒÉng nh·∫≠p'.")
                        except sqlite3.IntegrityError:
                            st.error("T√™n ƒëƒÉng nh·∫≠p n√†y ƒë√£ t·ªìn t·∫°i.")
                        except Exception as e:
                            st.error(f"L·ªói khi ƒëƒÉng k√Ω: {e}")

# --- N·∫øu ƒê√É ƒêƒÇNG NH·∫¨P ---
else:
    #=========================================================
    # PH·∫¶N 5: GIAO DI·ªÜN ·ª®NG D·ª§NG (CH√çNH)
    #=========================================================
    
    # --- THANH SIDEBAR ---
    st.sidebar.title(f"Ch√†o m·ª´ng, {st.session_state['name']}!")
    if st.sidebar.button("ƒêƒÉng xu·∫•t"):
        st.session_state['authentication_status'] = None
        st.session_state['username'] = None
        st.session_state['name'] = None
        st.rerun() 

    page = st.sidebar.radio("ƒêi·ªÅu h∆∞·ªõng:", ["Ph√¢n t√≠ch", "L·ªãch s·ª≠ c·ªßa t√¥i"])
    st.sidebar.markdown("---")
    
    # --- TRANG "PH√ÇN T√çCH" ---
    if page == "Ph√¢n t√≠ch":
        st.title(f"Trang Ph√¢n t√≠ch")

        # T√çNH NƒÇNG 1: PH√ÇN T√çCH TR·ª∞C TI·∫æP
        st.markdown("---")
        st.header("1. Ph√¢n t√≠ch Tr·ª±c ti·∫øp (Live Analysis)")
        # (Code t√≠nh nƒÉng 1 gi·ªØ nguy√™n)
        col1, col2 = st.columns([0.6, 0.4])
        with col1:
            user_input_eng = st.text_area("Nh·∫≠p m·ªôt b√¨nh lu·∫≠n Ti·∫øng Anh:", "This product is great!", height=100, key="eng_input")
            analyze_button_live = st.button("‚ú® Ph√¢n t√≠ch ngay!", key="live_button")
        with col2:
            st.markdown("### üîç K·∫øt qu·∫£ Ph√¢n t√≠ch")
            if analyze_button_live:
                if user_input_eng.strip() and model:
                    with st.spinner("ƒêang x·ª≠ l√Ω..."):
                        cleaned_input = clean_text_english(user_input_eng)
                        vectorized_input = vectorizer.transform([cleaned_input])
                        prediction = model.predict(vectorized_input)[0]
                        probability = model.predict_proba(vectorized_input)
                        confidence_score = np.max(probability)
                        label_text = "Positive" if prediction == 1 else "Negative"
                        
                        if prediction == 1: st.success("T√çCH C·ª∞C (Positive)")
                        else: st.error("TI√äU C·ª∞C (Negative)")
                        st.progress(confidence_score)
                        st.metric(label="ƒê·ªô t·ª± tin:", value=f"{confidence_score * 100:.2f} %")
                        
                        # Ch·ªâ l∆∞u l·ªãch s·ª≠ cho t√≠nh nƒÉng n√†y
                        save_history(st.session_state['username'], "Live", user_input_eng, label_text, confidence_score)

        # T√çNH NƒÇNG 2: PH√ÇN T√çCH D·ªÆ LI·ªÜU D√ÅN
        st.markdown("---")
        st.header("2. Ph√¢n t√≠ch D·ªØ li·ªáu D√°n (Paste-Box Analysis)")
        # (Code t√≠nh nƒÉng 2 gi·ªØ nguy√™n)
        paste_input = st.text_area("D√°n c√°c b√¨nh lu·∫≠n v√†o ƒë√¢y:", height=200, key="paste_input")
        analyze_button_paste = st.button("üöÄ Ph√¢n t√≠ch V√πng D·ªØ li·ªáu", key="paste_button")
        if analyze_button_paste:
            if paste_input.strip() and model:
                with st.spinner("ƒêang ph√¢n t√≠ch v√πng d·ªØ li·ªáu..."):
                    lines = paste_input.splitlines()
                    reviews = [line.strip() for line in lines if line.strip()]
                    if reviews:
                        df_paste = pd.DataFrame(reviews, columns=['text_to_analyze'])
                        df_paste['cleaned_text'] = df_paste['text_to_analyze'].apply(clean_text_english)
                        X_new = vectorizer.transform(df_paste['cleaned_text'])
                        predictions = model.predict(X_new)
                        df_paste['Sentiment_Result'] = predictions
                        df_paste['Sentiment_Label'] = df_paste['Sentiment_Result'].map({1: 'Positive', 0: 'Negative'})
                        
                        st.success(f"Ph√¢n t√≠ch ho√†n t·∫•t {len(df_paste)} b√¨nh lu·∫≠n!")
                        
                        pos_count = (df_paste['Sentiment_Result'] == 1).sum()
                        neg_count = len(df_paste) - pos_count
                        
                        # === ƒê√É X√ìA L·ªñI L∆ØU L·ªäCH S·ª¨ ·ªû ƒê√ÇY ===
                        
                        total_reviews = len(df_paste)
                        col_metric1, col_metric2 = st.columns(2)
                        col_metric1.metric("üëç Positive", f"{pos_count} ({pos_count/total_reviews:.1%})")
                        col_metric2.metric("üëé Negative", f"{neg_count} ({neg_count/total_reviews:.1%})")
                        fig = go.Figure(data=[go.Pie(labels=['Positive', 'Negative'],
                                                     values=[pos_count, neg_count],
                                                     marker={'colors': ['#28a745', '#dc3545']},
                                                     hole=.3)])
                        st.plotly_chart(fig, use_container_width=True)
                        st.dataframe(df_paste)

        # T√çNH NƒÇNG 3: PH√ÇN T√çCH H√ÄNG LO·∫†T (FILE)
        st.markdown("---")
        st.header("3. Ph√¢n t√≠ch H√†ng lo·∫°t (Batch Analysis)")
        # (Code t√≠nh nƒÉng 3 gi·ªØ nguy√™n)
        uploaded_file = st.file_uploader("Ch·ªçn file...", type=["csv", "xlsx"], key="eng_uploader")
        if uploaded_file and model:
            try:
                if uploaded_file.name.endswith('.xlsx'):
                    header_df = pd.read_excel(uploaded_file, nrows=1)
                else:
                    uploaded_file.seek(0)
                    header_df = pd.read_csv(uploaded_file, nrows=1)
                    uploaded_file.seek(0) 
                    
                available_cols = header_df.columns.tolist()
            except Exception as e:
                st.error(f"L·ªói khi ƒë·ªçc file: {e}")
                available_cols = []
                
            default_cols = [col for col in ['Review', 'Summary', 'text'] if col in available_cols]
            col1_index = 0
            if default_cols:
                try: col1_index = available_cols.index(default_cols[0])
                except ValueError: col1_index = 0 
            col2_index = 0
            if len(default_cols) > 1:
                try: col2_index = available_cols.index(default_cols[1]) + 1
                except ValueError: col2_index = 0
            col1 = st.selectbox("C·ªôt 1 (v√≠ d·ª•: 'Review')", available_cols, index=col1_index, key="col1_eng")
            col2 = st.selectbox("C·ªôt 2 (v√≠ d·ª•: 'Summary') (T√πy ch·ªçn)", [None] + available_cols, index=col2_index, key="col2_eng")

            
            if st.button("üìä B·∫Øt ƒë·∫ßu Ph√¢n t√≠ch File", key="eng_button"):
                with st.spinner("ƒêang ph√¢n t√≠ch file..."):
                    if uploaded_file.name.endswith('.csv'):
                        df = pd.read_csv(uploaded_file)
                    else:
                        df = pd.read_excel(uploaded_file)
                        
                    if col2 and col2 != 'None':
                        df['text_to_analyze'] = df[col1].astype(str).fillna('') + " " + df[col2].astype(str).fillna('')
                    else:
                        df['text_to_analyze'] = df[col1].astype(str).fillna('')
                    
                    df['cleaned_text'] = df['text_to_analyze'].apply(clean_text_english)
                    X_new = vectorizer.transform(df['cleaned_text'])
                    predictions = model.predict(X_new)
                    df['Sentiment_Result'] = predictions
                    df['Sentiment_Label'] = df['Sentiment_Result'].map({1: 'Positive', 0: 'Negative'})
                    
                    st.success("Ph√¢n t√≠ch file ho√†n t·∫•t!")
                    
                    pos_count = (df['Sentiment_Result'] == 1).sum()
                    neg_count = len(df) - pos_count
                    
                    # === ƒê√É X√ìA L·ªñI L∆ØU L·ªäCH S·ª¨ ·ªû ƒê√ÇY ===
                    
                    total_reviews = len(df)
                    col_metric1, col_metric2 = st.columns(2)
                    col_metric1.metric("üëç Positive", f"{pos_count} ({pos_count/total_reviews:.1%})")
                    col_metric2.metric("üëé Negative", f"{neg_count} ({neg_count/total_reviews:.1%})")
                    fig = go.Figure(data=[go.Pie(labels=['Positive', 'Negative'],
                                                 values=[pos_count, neg_count],
                                                 marker={'colors': ['#28a745', '#dc3545']},
                                                 hole=.3)])
                    st.plotly_chart(fig, use_container_width=True)
                    st.dataframe(df)
                    
                    @st.cache_data
                    def convert_df(df_to_convert):
                        return df_to_convert.to_csv(index=False).encode('utf-8')
                    csv_output = convert_df(df)
                    st.download_button(label="üì• T·∫£i v·ªÅ k·∫øt qu·∫£ (CSV)", data=csv_output,
                                       file_name="eng_sentiment_results.csv", mime="text/csv")


    # --- TRANG "L·ªäCH S·ª¨" ---
    elif page == "L·ªãch s·ª≠ c·ªßa t√¥i":
        st.header(f"L·ªãch s·ª≠ Ph√¢n t√≠ch c·ªßa {st.session_state['username']}")
        st.write("ƒê√¢y l√† c√°c ph√¢n t√≠ch g·∫ßn nh·∫•t c·ªßa b·∫°n (t·ª´ Ph√¢n t√≠ch Tr·ª±c ti·∫øp).")
        
        # L·∫•y l·ªãch s·ª≠ t·ª´ DB
        history_data = get_user_history(st.session_state['username'])
        
        if history_data.empty:
            st.info("B·∫°n ch∆∞a c√≥ l·ªãch s·ª≠ ph√¢n t√≠ch n√†o.")
        else:
            st.dataframe(history_data, use_container_width=True)